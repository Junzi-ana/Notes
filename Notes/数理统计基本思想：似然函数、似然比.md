---
{}
---
#SmallEssays/数理统计 

假设随机变量 $X$ 服从某单参数分布族，其概率密度是 $f(x;\theta)$。从数理统计的视角，$f(x;\theta)$ 是有双重含义的，一方面，它刻画了样本 $X$ 的分布是如何受到 $\theta$ 支配的，即**概率密度**；另一方面，它也刻画了 $X$ 的分布是如何揭示关于 $\theta$ 的信息的，即**似然函数**。这种对立统一的特点使其成为了数理统计中最重要的概念之一。

似然函数，在字面意思上，表示“看上去有多么像这么回事”的函数。更准确地说，不妨将 $f(x;\theta)$ 写成 $L(\theta;x)$ 来凸显主次关系，我们在看到数据 $x$ 时，这个 $\theta$ 的取值有多么“像这么回事”。比如，当我们投掷 $100$ 枚硬币，看到 $47$ 枚正面，即我们得到的数据为频率 $p=0.47$，此时这个硬币正面出现的概率 $\theta$ 看起来就比较像 $0.5$，而不太像 $0.9$，所以 $L(0.5;p)$ 就应该大于 $L(0.9,p)$ 。

如何度量似然性？这涉及到数理统计中的一个基本的信条：我们之所以能观测到样本 $x$，是因为 $x$ 出现的概率大。当 $f(x;\theta)$ 小时，说明这个 $\theta$ 的取值“看上去不太像”，因此 $L(\theta;x)$ 也小，反之亦然。于是，直接定义 $L(\theta;x)=f(x;\theta)$ 为似然函数是合理的。与此同时，我们可以对于给定的样本 $x$，选出看上去最像的 $\hat{\theta}$ 作为 $\theta$ 的估计，这就是**极大似然估计**，即
$$
\hat{\theta}_{\text{MLE}}=\underset{\theta}{\text{argmax}} ~L(\theta;x)
$$

与贝叶斯分析框架不同，似然函数并非概率分布，其绝对取值是没有实际意义的，只能用于比较不同 $\theta$ 取值的似然性大小。从这个角度出发，我们便开始考虑两个似然函数的比值，即**似然比**。似然比可以认为是极大似然估计在假设检验中的引申。

涉及假设检验的知识，大部分统计学的初学者只学过正态总体的均值、方差检验。事实上这只能说是统计学的预热，并没有真正进入核心，因为一旦脱离了正态总体的假定，即使知道构造枢轴量的技巧，也难以下手。相比之下，极大似然估计却是一个几乎通用的求取点估计的手段。如何将它引申到假设检验问题？

考虑简单假设检验问题
$$
H_{0}:\theta =\theta_{0}\leftrightarrow H_{1}:\theta =\theta_{1}
$$
并将似然比定义为 $\lambda=\frac{L(\theta_{1};x)}{L(\theta_{0} ;x)}$ 。它的统计意义是直观的，$\lambda$ 越大表示数据 $x$ 越支持 $H_{1}$，反之 $x$ 越支持 $H_{0}$ 。那么 $\lambda$ 多大才算大？大到什么程度才足以否定 $H_{0}$ ？换言之，设定检验统计量
$$
\phi(x)=\left\{\begin{aligned}
1,\quad \lambda>c\\
r,\quad \lambda=c
\\0,\quad \lambda<c
\end{aligned}\right.
$$
其中 $c$ 是一个常数，表示临界值，根据显著性水平 $\alpha$ 确定。这个 $c$ 具体如何确定不是一件简单的事情，这需要确定 $\lambda$ 的分布。但幸运的是，Wilks 证明了在一定条件下，**$2\ln\lambda$ 的极限分布是 $\chi^{2}$ 分布**，从而可以近似确定 $c$ 。因此似然比检验基本上是大样本检验。关于 Wilks 定理，详见笔记[[似然比检验的 Wilks 定理]]。

对于复合假设检验问题
$$
H_{0}:\theta =\Theta_{0}\leftrightarrow H_{1}:\theta =\Theta_{1}
$$
一个想法是，在 $\Theta_{0}$ 和 $\Theta_{1}$ 中取一个最具代表性的元素，而最具代表性的自然就是极大似然估计了。此时似然比应定义为 
$$
\lambda=\frac{\sup_{\theta \in\Theta}L(\theta;x)}{\sup_{\theta \in\Theta_{0}}L(\theta ;x)}
$$
这里做了一个轻微的修改：分子并没有对 $\theta \in\Theta_{1}$ 取上确界，而是对 $\theta \in\Theta$ 。这个修改是为了计算方便，而非本质的，剩下的和简单情形类似。

---
*2025-9-29*
